An End-to-End Learning based Control Signal Prediction for Autonomous Robotic Colonoscopy
Van Sy Nguyen (nguyenvansy240@gmail.com), Bohyun Hwang (hbh_92@nate.com), Byungkyu Kim (bkim@kau.ac.kr), JaeHoon Jung (jhjung@kau.ac.kr)

1 - The video show the experiments of 4 methods in Autonomous Robotic Colonoscopy.
Link: https://youtu.be/uJQPiWEXQQY

2 - There are three datasets:
Dataset 1: 27 Experiments were created by an operator who manually controls the colonoscope from rectum to cecum on Colonoscopy Training Simulator. 
Each colon image is annotated with a target point (represented by a white dot) and assigned a class (either class 0 or class 1) 
Dataset 2: 12 Experiments were made by the autonomous operation using IMAGE-BASED VISUAL SERVO CONTROL.
Dataset 3: 30 Experiments created by executing the autonomous operation using IMAGE-BASED VISUAL SERVO CONTROL. 
The colon images and all control signals were saved.

Datasetlink :https://drive.google.com/file/d/1HoWwhCBQ3RLgQT_hPsKgh5dNkoCfPPc2/view?usp=share_link

3 - Source code of three datasets is provided accordingly.

4 - The system for our training and experiments
Ubuntu 20.04.5 
NVIDIA Corporation / Mesa Intel® Graphics (RKL GT1)
11th Gen Intel® Core™ i5-11600K @ 3.90GHz × 12 
Python 3.6.13
CuDa 11.1

